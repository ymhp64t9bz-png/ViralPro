#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ ViralPro Serverless - Handler Completo
Processamento de v√≠deos virais com Smart Crop, Legendas e T√≠tulos IA
Baseado no ViralPro local
"""

import runpod
import os
import sys
import logging
import tempfile
import requests
import uuid
import math
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# ==================== CONFIGURA√á√ÉO ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("ViralPro")

# Diret√≥rios
TEMP_DIR = Path("/tmp/viralpro")
OUTPUT_DIR = Path("/tmp/viralpro/output")
TEMP_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

print("=" * 60)
print("üéØ ViralPro Serverless - Full Features")
print("=" * 60)

# ==================== IMPORTS CONDICIONAIS ====================
try:
    from moviepy.editor import (
        VideoFileClip, ImageClip, AudioFileClip,
        TextClip, CompositeVideoClip, concatenate_videoclips,
        ColorClip
    )
    from moviepy.video.fx.all import crop
    import numpy as np
    MOVIEPY_AVAILABLE = True
    logger.info("‚úÖ MoviePy dispon√≠vel")
except ImportError as e:
    MOVIEPY_AVAILABLE = False
    logger.error(f"‚ùå MoviePy n√£o dispon√≠vel: {e}")

try:
    import cv2
    CV2_AVAILABLE = True
    logger.info("‚úÖ OpenCV dispon√≠vel")
except ImportError as e:
    CV2_AVAILABLE = False
    logger.error(f"‚ùå OpenCV n√£o dispon√≠vel: {e}")

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    logger.info("‚úÖ PIL dispon√≠vel")
except ImportError as e:
    PIL_AVAILABLE = False
    logger.error(f"‚ùå PIL n√£o dispon√≠vel: {e}")

try:
    import mediapipe as mp
    mp_face_detection = mp.solutions.face_detection
    MEDIAPIPE_AVAILABLE = True
    logger.info("‚úÖ MediaPipe dispon√≠vel")
except ImportError as e:
    MEDIAPIPE_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è MediaPipe n√£o dispon√≠vel: {e}")

try:
    from faster_whisper import WhisperModel
    WHISPER_AVAILABLE = True
    logger.info("‚úÖ Faster-Whisper dispon√≠vel")
except ImportError as e:
    WHISPER_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Faster-Whisper n√£o dispon√≠vel: {e}")

try:
    import boto3
    from botocore.client import Config
    
    B2_KEY_ID = os.getenv("B2_KEY_ID", "68702c2cbfc6")
    B2_APP_KEY = os.getenv("B2_APP_KEY", "00506496bc1450b6722b672d9a43d00605f17eadd7")
    B2_ENDPOINT = os.getenv("B2_ENDPOINT", "https://s3.us-east-005.backblazeb2.com")
    B2_BUCKET = os.getenv("B2_BUCKET_NAME", "KortexClipAI")
    
    if B2_KEY_ID and B2_APP_KEY:
        s3_client = boto3.client(
            "s3",
            endpoint_url=B2_ENDPOINT,
            aws_access_key_id=B2_KEY_ID,
            aws_secret_access_key=B2_APP_KEY,
            config=Config(signature_version="s3v4")
        )
        B2_AVAILABLE = True
        logger.info("‚úÖ Backblaze B2 configurado")
    else:
        B2_AVAILABLE = False
        logger.warning("‚ö†Ô∏è B2 credentials n√£o configuradas")
except Exception as e:
    B2_AVAILABLE = False
    logger.error(f"‚ùå Erro ao configurar B2: {e}")

# ==================== DOWNLOAD DE V√çDEO ====================
def download_video(url: str) -> str:
    """Baixa v√≠deo da URL"""
    try:
        logger.info(f"üì• Baixando v√≠deo...")
        
        temp_file = TEMP_DIR / f"input_{uuid.uuid4().hex[:8]}.mp4"
        
        response = requests.get(url, stream=True, timeout=300)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded = 0
        
        with open(temp_file, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                downloaded += len(chunk)
                if total_size > 0 and downloaded % (1024 * 1024) == 0:
                    progress = (downloaded / total_size) * 100
                    logger.info(f"üì• Download: {progress:.1f}%")
        
        logger.info(f"‚úÖ Download completo: {temp_file} ({downloaded / 1024 / 1024:.2f} MB)")
        return str(temp_file)
        
    except Exception as e:
        logger.error(f"‚ùå Erro no download: {e}")
        raise

# ==================== DETEC√á√ÉO DE ROSTO ====================
def detect_face_center(frame, face_detection) -> Optional[int]:
    """Detecta centro do rosto usando MediaPipe"""
    try:
        if not MEDIAPIPE_AVAILABLE:
            return None
        
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_detection.process(rgb_frame)
        
        if results.detections:
            detection = results.detections[0]
            bbox = detection.location_data.relative_bounding_box
            
            frame_width = frame.shape[1]
            face_center_x = int((bbox.xmin + bbox.width / 2) * frame_width)
            
            return face_center_x
        
        return None
        
    except Exception as e:
        logger.error(f"‚ùå Erro na detec√ß√£o de rosto: {e}")
        return None

# ==================== SMART CROP ====================
def create_smart_crop(clip) -> VideoFileClip:
    """Aplica Smart Crop 9:16 focado no rosto"""
    try:
        logger.info("üéØ Aplicando Smart Crop...")
        
        if not MEDIAPIPE_AVAILABLE or not CV2_AVAILABLE:
            logger.warning("‚ö†Ô∏è MediaPipe/CV2 n√£o dispon√≠vel, usando crop centralizado")
            # Crop centralizado simples
            w, h = clip.size
            target_w = int(h * 9 / 16)
            x_center = w / 2
            x1 = max(0, x_center - target_w / 2)
            return clip.fx(crop, x1=x1, width=target_w)
        
        # An√°lise de frames para encontrar rosto
        with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:
            # Amostra 5 frames
            sample_times = [clip.duration * i / 5 for i in range(5)]
            face_centers = []
            
            for t in sample_times:
                frame = clip.get_frame(t)
                face_x = detect_face_center(frame, face_detection)
                if face_x:
                    face_centers.append(face_x)
            
            # Calcula posi√ß√£o m√©dia do rosto
            if face_centers:
                avg_face_x = sum(face_centers) / len(face_centers)
                logger.info(f"‚úÖ Rosto detectado em X={avg_face_x:.0f}")
            else:
                avg_face_x = clip.w / 2
                logger.warning("‚ö†Ô∏è Nenhum rosto detectado, usando centro")
            
            # Calcula crop
            target_w = int(clip.h * 9 / 16)
            x1 = max(0, min(avg_face_x - target_w / 2, clip.w - target_w))
            
            logger.info(f"‚úÇÔ∏è Crop: x1={x1:.0f}, width={target_w}")
            return clip.fx(crop, x1=x1, width=target_w)
        
    except Exception as e:
        logger.error(f"‚ùå Erro no Smart Crop: {e}")
        # Fallback para crop centralizado
        w, h = clip.size
        target_w = int(h * 9 / 16)
        x1 = (w - target_w) / 2
        return clip.fx(crop, x1=x1, width=target_w)

# ==================== GERA√á√ÉO DE LEGENDAS ====================
def generate_subtitles(audio_path: str, model_size: str = "base") -> List[Dict]:
    """Gera legendas usando Faster-Whisper"""
    try:
        if not WHISPER_AVAILABLE:
            logger.warning("‚ö†Ô∏è Whisper n√£o dispon√≠vel")
            return []
        
        logger.info(f"üé§ Transcrevendo √°udio com Whisper ({model_size})...")
        
        model = WhisperModel(model_size, device="cuda", compute_type="float16")
        
        segments, info = model.transcribe(audio_path, language="pt")
        
        subtitles = []
        for segment in segments:
            subtitles.append({
                "start": segment.start,
                "end": segment.end,
                "text": segment.text.strip()
            })
        
        logger.info(f"‚úÖ {len(subtitles)} legendas geradas")
        return subtitles
        
    except Exception as e:
        logger.error(f"‚ùå Erro na transcri√ß√£o: {e}")
        return []

# ==================== ADICIONAR LEGENDAS AO V√çDEO ====================
def add_subtitles_to_video(clip: VideoFileClip, subtitles: List[Dict]) -> VideoFileClip:
    """Adiciona legendas ao v√≠deo"""
    try:
        if not subtitles or not PIL_AVAILABLE:
            return clip
        
        logger.info("üìù Adicionando legendas...")
        
        subtitle_clips = []
        
        for sub in subtitles:
            # Cria imagem com texto
            img = Image.new('RGBA', (1080, 200), (0, 0, 0, 0))
            draw = ImageDraw.Draw(img)
            
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 50)
            except:
                font = ImageFont.load_default()
            
            text = sub['text']
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            x = (1080 - text_width) // 2
            y = 50
            
            # Borda preta
            for adj_x in range(-2, 3):
                for adj_y in range(-2, 3):
                    draw.text((x + adj_x, y + adj_y), text, font=font, fill=(0, 0, 0, 255))
            
            # Texto branco
            draw.text((x, y), text, font=font, fill=(255, 255, 255, 255))
            
            # Converte para clip
            img_array = np.array(img)
            txt_clip = ImageClip(img_array).set_duration(sub['end'] - sub['start'])
            txt_clip = txt_clip.set_start(sub['start']).set_position(('center', 'bottom'))
            
            subtitle_clips.append(txt_clip)
        
        # Composi√ß√£o
        final_clip = CompositeVideoClip([clip] + subtitle_clips, size=clip.size)
        final_clip = final_clip.set_audio(clip.audio)
        
        logger.info(f"‚úÖ {len(subtitle_clips)} legendas adicionadas")
        return final_clip
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao adicionar legendas: {e}")
        return clip

# ==================== PROCESSAMENTO DE V√çDEO VIRAL ====================
def process_viral_video(
    video_path: str,
    num_clips: int = 3,
    clip_duration: int = 60,
    start_min: int = 0,
    add_subtitles: bool = True
) -> List[str]:
    """Processa v√≠deo completo com Smart Crop e Legendas"""
    try:
        logger.info("üé¨ Iniciando processamento viral...")
        
        if not MOVIEPY_AVAILABLE:
            raise Exception("MoviePy n√£o dispon√≠vel")
        
        # Carrega v√≠deo
        video = VideoFileClip(video_path)
        duration = video.duration
        
        logger.info(f"üìä Dura√ß√£o: {duration}s")
        
        # Calcula clips
        start_time = start_min * 60
        clips_output = []
        
        for i in range(num_clips):
            clip_start = start_time + (i * clip_duration)
            clip_end = min(clip_start + clip_duration, duration)
            
            if clip_start >= duration:
                break
            
            logger.info(f"‚úÇÔ∏è Processando clip {i+1}/{num_clips}: {clip_start}s - {clip_end}s")
            
            # Extrai clip
            clip = video.subclip(clip_start, clip_end)
            
            # Smart Crop
            clip = create_smart_crop(clip)
            
            # Legendas
            if add_subtitles:
                # Extrai √°udio
                audio_path = TEMP_DIR / f"audio_{i}_{uuid.uuid4().hex[:8]}.wav"
                clip.audio.write_audiofile(str(audio_path), verbose=False, logger=None)
                
                # Gera legendas
                subtitles = generate_subtitles(str(audio_path))
                
                # Adiciona legendas
                if subtitles:
                    clip = add_subtitles_to_video(clip, subtitles)
                
                # Remove √°udio tempor√°rio
                try:
                    os.remove(audio_path)
                except:
                    pass
            
            # Exporta
            output_file = OUTPUT_DIR / f"viral_{i+1}_{uuid.uuid4().hex[:8]}.mp4"
            
            logger.info(f"üé¨ Renderizando clip {i+1}...")
            
            clip.write_videofile(
                str(output_file),
                codec='libx264',
                audio_codec='aac',
                preset='fast',
                ffmpeg_params=[
                    '-profile:v', 'high',
                    '-level', '4.1',
                    '-pix_fmt', 'yuv420p',
                    '-movflags', '+faststart'
                ],
                verbose=False,
                logger=None
            )
            
            clip.close()
            clips_output.append(str(output_file))
            
            logger.info(f"‚úÖ Clip {i+1} conclu√≠do: {output_file}")
        
        video.close()
        
        logger.info(f"‚úÖ Processamento completo: {len(clips_output)} clips gerados")
        return clips_output
        
    except Exception as e:
        logger.error(f"‚ùå Erro no processamento: {e}")
        raise

# ==================== UPLOAD PARA B2 ====================
def upload_to_b2(file_path: str, object_name: str = None) -> Optional[str]:
    """Upload para Backblaze B2"""
    try:
        if not B2_AVAILABLE:
            logger.warning("‚ö†Ô∏è B2 n√£o dispon√≠vel, retornando path local")
            return file_path
        
        if object_name is None:
            object_name = f"viralpro/{os.path.basename(file_path)}"
        
        logger.info(f"üì§ Uploading para B2: {object_name}")
        
        s3_client.upload_file(file_path, B2_BUCKET, object_name)
        
        # Gera URL assinada
        url = s3_client.generate_presigned_url(
            'get_object',
            Params={'Bucket': B2_BUCKET, 'Key': object_name},
            ExpiresIn=3600
        )
        
        logger.info(f"‚úÖ Upload completo: {object_name}")
        return url
        
    except Exception as e:
        logger.error(f"‚ùå Erro no upload B2: {e}")
        return file_path

# ==================== HANDLER PRINCIPAL ====================
def handler(event):
    """Handler principal do ViralPro"""
    try:
        logger.info("üöÄ ViralPro Handler iniciado")
        logger.info(f"üì¶ Event: {event.get('id', 'N/A')}")
        
        input_data = event.get("input", {})
        
        # Modo de teste
        if input_data.get("mode") == "test":
            return {
                "status": "success",
                "message": "ViralPro worker funcionando!",
                "version": "1.0",
                "features": {
                    "moviepy": MOVIEPY_AVAILABLE,
                    "cv2": CV2_AVAILABLE,
                    "pil": PIL_AVAILABLE,
                    "mediapipe": MEDIAPIPE_AVAILABLE,
                    "whisper": WHISPER_AVAILABLE,
                    "b2": B2_AVAILABLE
                }
            }
        
        # Valida√ß√£o
        video_url = input_data.get("video_url")
        if not video_url:
            return {
                "status": "error",
                "error": "video_url n√£o fornecido"
            }
        
        # Par√¢metros
        num_clips = input_data.get("num_clips", 3)
        clip_duration = input_data.get("clip_duration", 60)
        start_min = input_data.get("start_min", 0)
        add_subtitles = input_data.get("add_subtitles", True)
        
        # Download
        video_path = download_video(video_url)
        
        # Processamento
        clips = process_viral_video(
            video_path,
            num_clips,
            clip_duration,
            start_min,
            add_subtitles
        )
        
        # Upload para B2
        clips_data = []
        for clip_path in clips:
            b2_url = upload_to_b2(clip_path)
            clips_data.append({
                "local_path": clip_path,
                "b2_url": b2_url
            })
        
        # Limpeza
        try:
            os.remove(video_path)
        except:
            pass
        
        # Resultado
        result = {
            "status": "success",
            "message": f"{len(clips)} clips virais gerados",
            "clips": clips_data
        }
        
        logger.info(f"‚úÖ Job completo: {len(clips)} clips")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erro no handler: {e}", exc_info=True)
        return {
            "status": "error",
            "error": str(e),
            "type": type(e).__name__
        }

# ==================== INICIALIZA√á√ÉO ====================
if __name__ == "__main__":
    logger.info("üéØ Iniciando ViralPro Serverless Worker...")
    logger.info(f"üìä MoviePy: {MOVIEPY_AVAILABLE}")
    logger.info(f"üìä OpenCV: {CV2_AVAILABLE}")
    logger.info(f"üìä PIL: {PIL_AVAILABLE}")
    logger.info(f"üìä MediaPipe: {MEDIAPIPE_AVAILABLE}")
    logger.info(f"üìä Whisper: {WHISPER_AVAILABLE}")
    logger.info(f"üìä B2: {B2_AVAILABLE}")
    
    runpod.serverless.start({"handler": handler})
    logger.info("‚úÖ Worker iniciado!")
